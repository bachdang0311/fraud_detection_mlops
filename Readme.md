# MLOps Project: Real-time Fraud Detection System

## 1. Project Architecture

**(Your architecture diagram image will go here)**

---

## 2. Introduction

### 2.1. Project Goal
The primary objective of this MLOps project is to design, develop, and deploy an end-to-end machine learning system capable of detecting fraudulent financial transactions in real-time. This encompasses the entire machine learning lifecycle, including automated data preprocessing, robust feature engineering, model training, comprehensive experiment tracking, and the deployment of the trained model as a scalable, containerized web service with Continuous Integration and Continuous Deployment (CI/CD) pipelines.

### 2.2. Technologies Used
This project leverages a modern stack of MLOps tools and technologies:
* **Programming Language:** Python 3.11
* **Core Data Science Libraries:** Pandas, NumPy, Scikit-learn, LightGBM
* **Visualization:** Matplotlib, Seaborn
* **Model & Preprocessor Persistence:** Joblib
* **Experiment Tracking (Local):** MLflow
* **Web Framework & API:** Flask
* **Containerization:** Docker
* **Cloud Platform:** Microsoft Azure
    * **Azure App Service for Containers:** Hosting the containerized Flask API.
    * **Azure Container Registry (ACR):** Storing Docker images.
    * **Azure Application Insights:** Application performance monitoring and logging.
* **CI/CD:** GitHub Actions
* **Version Control:** Git & GitHub

### 2.3. Main Functionalities
The system implements the following key functionalities:
1.  **Automated Training Pipeline (`run_pipeline.py`):**
    * Loads and merges raw transaction and identity data.
    * Performs data preprocessing, including datetime feature extraction, M-feature mapping, string cleaning, and label encoding for categorical features.
    * Conducts extensive feature engineering, such as UID creation, D-normalized features, C-column aggregations, V-column PCA, and M-flag aggregates.
    * Trains a LightGBM model for fraud classification.
    * Logs training parameters, evaluation metrics (AUC, LogLoss, F1-score, Precision, Recall), and various artifacts (trained model, preprocessors, feature lists, evaluation plots) locally using MLflow.
    * Saves the trained model, preprocessors, and other essential artifacts for deployment.
2.  **Real-time Fraud Prediction API (`src/predict.py` with Flask):**
    * Exposes a RESTful API endpoint (`/api/predict`) that accepts transaction details in JSON format.
    * Applies the same preprocessing and feature engineering transformations to the input data as used during training, ensuring consistency.
    * Loads the persisted LightGBM model and associated preprocessors.
    * Returns a JSON response containing the fraud probability and a binary fraud/not-fraud prediction.
    * Optionally, serves a simple HTML web interface via the `/` route for manual data entry and prediction.
3.  **Containerized Deployment on Azure App Service:**
    * The Flask API, along with all its dependencies, model, and preprocessors, is containerized using Docker.
    * The resulting Docker image is stored in Azure Container Registry (ACR).
    * The application is deployed and hosted on Azure App Service for Containers, providing a scalable and managed environment for the API.
4.  **CI/CD with GitHub Actions:**
    * An automated workflow is triggered upon pushing code changes to the `main` branch of the GitHub repository.
    * The workflow automatically builds a new Docker image.
    * The new Docker image is automatically pushed to ACR.
    * The Azure App Service is automatically updated to use the latest image from ACR, ensuring continuous deployment.
5.  **Monitoring and Logging:**
    * Integration with Azure Application Insights for real-time monitoring of the deployed application's performance, availability, error rates, and for querying application logs (including custom traces from the Python code).
    * Local MLflow UI for reviewing, comparing, and analyzing past training experiments.

---

## 3. Project Structure
<img width="1202" alt="Screenshot 2025-05-09 175741" src="https://github.com/user-attachments/assets/6739cda6-5cee-4b1d-a267-d8fc91fc5bf6" />

**Folder and File Descriptions:**

* **`.github/workflows/`**: Contains the GitHub Actions workflow YAML file (`deploy-to-azure-app-service.yml`) that defines the CI/CD pipeline for building the Docker image, pushing it to ACR, and deploying it to Azure App Service.
* **`artifacts/`**: Stores non-model outputs generated by the training pipeline. This includes:
    * `confusion_matrix_valid.png`: Visualization of the model's performance on the validation set.
    * `feature_importance.png`: Plot showing the most important features for the model.
    * `final_training_features.json`: A JSON file listing the exact features used to train the model, crucial for ensuring consistency during inference.
    * `model_info.json`: A JSON file containing metadata about the trained model, such as MLflow run ID, training parameters, and key performance metrics.
* **`data/raw/`**: Designated directory for storing the original, unaltered input datasets (e.g., `train_transaction.csv`, `train_identity.csv`). These files are typically large and are not committed to the Git repository.
* **`data/processed/`**: Intended for storing dataframes after preprocessing and feature engineering steps, ready for model training (e.g., `final_processed_training_data.parquet`). Also generally not committed to Git.
* **`env/`**: Contains environment configuration files. `environment_scoring.yml` was likely used for defining a Conda environment for a previous Azure Machine Learning deployment approach.
* **`mlruns/`**: The default local directory where MLflow stores all experiment tracking data, including parameters, metrics, tags, and artifacts for each run. This directory is excluded from Git.
* **`models/`**: This critical directory stores the serialized trained machine learning model (`lgbm_model.joblib`) and any preprocessor objects (`label_encoders.joblib`, `pca_v_transformer.joblib`, `scaler_v_transformer.joblib`) that were fitted during the training pipeline and are necessary for transforming new data at inference time.
* **`notebooks/`**: Contains Jupyter notebooks (`fraud_ml_ops.ipynb`) used for initial data exploration, analysis, experimentation, and iterative model development.
* **`src/`**: The primary directory containing all Python source code for the project.
    * `__init__.py`: Marks the `src` directory as a Python package.
    * `config.py`: Defines global configuration variables, file paths, model hyperparameters, and other settings used throughout the project.
    * `data_preprocessing.py`: Houses functions responsible for loading raw data, cleaning it, handling missing values, and performing initial transformations like datetime processing and categorical encoding.
    * `feature_engineering.py`: Contains scripts for generating new, informative features from the preprocessed data to improve model performance.
    * `predict.py`: Implements the Flask web application. It loads the trained model and preprocessors, defines API endpoints (like `/api/predict`) for receiving input data, processes the input, makes predictions, and returns the results. It also serves the HTML interface.
    * `train.py`: Includes the core logic for training the LightGBM model, performing model evaluation on validation/test sets, and logging all relevant experiment details to MLflow locally.
    * `utils.py`: A collection of utility functions that support various tasks across the project, such as memory optimization.
* **`templates/`**: Contains HTML files (e.g., `index.html`) used by the Flask application to render a web-based user interface for making predictions.
* **`tests/`**: (To be developed) This directory will contain all unit tests and integration tests to ensure the correctness and reliability of the codebase.
* **Root Directory Files:**
    * `.dockerignore`: Specifies which files and directories should be excluded from the Docker build context to keep the image lean.
    * `.gitignore`: Lists files and directories that Git should ignore (e.g., virtual environments, local data, MLflow runs, sensitive configuration files).
    * `config.json`: Contains configuration details for connecting to an Azure Machine Learning workspace. *This file should be in `.gitignore` if it holds sensitive subscription or workspace IDs to avoid committing them to a public repository.*
    * `create_aml_scoring_env.py`, `deploy_to_aml_endpoint.py`, `register_aml_deployment_package.py`: These Python scripts were part of the initial MLOps strategy focused on deploying the model using Azure Machine Learning managed online endpoints. They handle the creation of scoring environments, registration of deployment packages, and deployment to AML endpoints. (Mention if these are now considered legacy or an alternative deployment path for specific scenarios).
    * `Dockerfile`: Contains the set of instructions for Docker to build the application image. It specifies the base Python image, copies necessary files (source code, models, artifacts, requirements), installs dependencies, and defines the command to run the Flask application.
    * `README.md`: This file, providing a comprehensive overview of the project.
    * `requirements.txt`: Lists all Python libraries and their versions required to run the project, ensuring a reproducible environment.
    * `run_pipeline.py`: The main executable script that orchestrates the entire local training pipeline. It calls functions from `data_preprocessing.py`, `feature_engineering.py`, and `train.py` in sequence to process data and train the model.
 
## 4. Installation, Setup, and Deployment Workflow
This section provides a concise guide to set up the project, run the training pipeline, and deploy the application to Azure App Service with CI/CD. Python 3.11 is required.

***Local Development & Training***
****1. Clone Repository & Setup Environment:****
git clone https://github.com/bachdang0311/fraud_detection_mlops.git && cd fraud_detection_mlops
Create and activate a Python virtual environment (e.g., python -m venv venv, then activate).
Install dependencies: pip install -r requirements.txt (ensure opencensus-ext-azure is included).
****2.Prepare Data:****
Download train_transaction.csv and train_identity.csv.
Place them in the data/raw/ directory.

****3. Run Training Pipeline:****
Execute: python run_pipeline.py
This generates:
Model and preprocessor files in models/.
Artifacts (feature lists, info, plots) in artifacts/.
MLflow experiment logs in mlruns/.

****4.Review Experiments (Optional):****
Run mlflow ui and navigate to http://localhost:5000.

****5.Test API Locally (Optional):****
Run python -m src.predict.
Test http://localhost:8080/api/predict with Postman or curl.

****6.Build Docker Image Locally (Recommended before first cloud push):****
docker build -t fraud_detector_app_local:latest .
(Optional) Test with docker run -p 8080:8080 -e PORT=8080 fraud_detector_app_local:latest

***II. Azure Resource Provisioning (One-time Manual Setup)***
(Ensure Azure CLI is installed & logged in: az login, az account set ...)

****7.Register Azure Providers (If needed):****

az provider register --namespace Microsoft.Web --wait
az provider register --namespace Microsoft.ContainerRegistry --wait
Create Azure Resources (if they don't exist, use your actual names and region like westus2):

Resource Group (e.g., MyFraudRgAppService): az group create --name <YourResourceGroup> --location <YourLocation>
Container Registry (ACR) (e.g., myfraudappacrhqbdz1): az acr create --resource-group <YourResourceGroup> --name <YourUniqueACRName> --sku Basic --admin-enabled true
App Service Plan (e.g., myFraudAppPlanWestprsxnj, SKU B1, Linux): az appservice plan create --name <YourAppServicePlanName> --resource-group <YourResourceGroup> --sku B1 --is-linux --location <YourLocation>
Web App for Containers (e.g., myfrauddetectorapik0jegk): az webapp create --resource-group <YourResourceGroup> --plan <YourAppServicePlanName> --name <YourUniqueWebAppName> --deployment-container-image-name "" az webapp config appsettings set --resource-group <YourResourceGroup> --name <YourUniqueWebAppName> --settings WEBSITES_PORT=8080
Enable Application Insights:

In Azure Portal: Navigate to your Web App -> "Application Insights" -> "Turn on Application Insights". Link or create a new resource.
III. CI/CD Setup with GitHub Actions (One-time Setup)
Prepare Azure Credentials for GitHub Actions:

ACR Admin Credentials: From ACR -> "Access keys" -> Enable Admin user -> Copy Login server, Username, Password.
App Service Publish Profile: From Web App -> "Get publish profile" -> Download .PublishSettings file -> Copy entire XML content.
Add Credentials to GitHub Secrets:

In your GitHub repo: "Settings" -> "Secrets and variables" -> "Actions" -> "New repository secret".
Add: ACR_LOGIN_SERVER, ACR_USERNAME, ACR_PASSWORD, AZURE_WEBAPP_PUBLISH_PROFILE, AZURE_APP_NAME (your Web App name), IMAGE_NAME (e.g., fraud_detector_app).
Create GitHub Actions Workflow File:

Create .github/workflows/deploy-to-azure-app-service.yml.
Paste the previously discussed YAML content (using ACR Admin User & Publish Profile).
Commit & Push Project to GitHub:

Ensure all necessary files are present (Dockerfile, src/, models/, artifacts/, workflow file, etc.).
Commit any uncommitted changes (especially model files if following "commit artifacts to Git" approach and the new workflow file).
Bash

git add .
git commit -m "Configure CI/CD with GitHub Actions"
git push origin main
IV. Automated Deployment via CI/CD (Ongoing)
Develop & Push Changes:

Make code modifications or re-run python run_pipeline.py to update models/artifacts.
Commit all relevant changes (including new model/artifact files) to Git.
git push origin main
Monitor CI/CD & Verify Deployment:

The GitHub Actions workflow will automatically build, push to ACR, and deploy to Azure App Service. Monitor this in your GitHub repo's "Actions" tab.
After successful deployment, test your Web App URL and API endpoints.
Check Azure Application Insights for logs and performance.
