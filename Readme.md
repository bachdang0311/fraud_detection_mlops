# MLOps Project: Real-time Fraud Detection System

## 1. Project Architecture

**(Your architecture diagram image will go here)**

---

## 2. Introduction

### 2.1. Project Goal
The primary objective of this MLOps project is to design, develop, and deploy an end-to-end machine learning system capable of detecting fraudulent financial transactions in real-time. This encompasses the entire machine learning lifecycle, including automated data preprocessing, robust feature engineering, model training, comprehensive experiment tracking, and the deployment of the trained model as a scalable, containerized web service with Continuous Integration and Continuous Deployment (CI/CD) pipelines.

### 2.2. Technologies Used
This project leverages a modern stack of MLOps tools and technologies:
* **Programming Language:** Python 3.11
* **Core Data Science Libraries:** Pandas, NumPy, Scikit-learn, LightGBM
* **Visualization:** Matplotlib, Seaborn
* **Model & Preprocessor Persistence:** Joblib
* **Experiment Tracking (Local):** MLflow
* **Web Framework & API:** Flask
* **Containerization:** Docker
* **Cloud Platform:** Microsoft Azure
    * **Azure App Service for Containers:** Hosting the containerized Flask API.
    * **Azure Container Registry (ACR):** Storing Docker images.
    * **Azure Application Insights:** Application performance monitoring and logging.
* **CI/CD:** GitHub Actions
* **Version Control:** Git & GitHub

### 2.3. Main Functionalities
The system implements the following key functionalities:
1.  **Automated Training Pipeline (`run_pipeline.py`):**
    * Loads and merges raw transaction and identity data.
    * Performs data preprocessing, including datetime feature extraction, M-feature mapping, string cleaning, and label encoding for categorical features.
    * Conducts extensive feature engineering, such as UID creation, D-normalized features, C-column aggregations, V-column PCA, and M-flag aggregates.
    * Trains a LightGBM model for fraud classification.
    * Logs training parameters, evaluation metrics (AUC, LogLoss, F1-score, Precision, Recall), and various artifacts (trained model, preprocessors, feature lists, evaluation plots) locally using MLflow.
    * Saves the trained model, preprocessors, and other essential artifacts for deployment.
2.  **Real-time Fraud Prediction API (`src/predict.py` with Flask):**
    * Exposes a RESTful API endpoint (`/api/predict`) that accepts transaction details in JSON format.
    * Applies the same preprocessing and feature engineering transformations to the input data as used during training, ensuring consistency.
    * Loads the persisted LightGBM model and associated preprocessors.
    * Returns a JSON response containing the fraud probability and a binary fraud/not-fraud prediction.
    * Optionally, serves a simple HTML web interface via the `/` route for manual data entry and prediction.
3.  **Containerized Deployment on Azure App Service:**
    * The Flask API, along with all its dependencies, model, and preprocessors, is containerized using Docker.
    * The resulting Docker image is stored in Azure Container Registry (ACR).
    * The application is deployed and hosted on Azure App Service for Containers, providing a scalable and managed environment for the API.
4.  **CI/CD with GitHub Actions:**
    * An automated workflow is triggered upon pushing code changes to the `main` branch of the GitHub repository.
    * The workflow automatically builds a new Docker image.
    * The new Docker image is automatically pushed to ACR.
    * The Azure App Service is automatically updated to use the latest image from ACR, ensuring continuous deployment.
5.  **Monitoring and Logging:**
    * Integration with Azure Application Insights for real-time monitoring of the deployed application's performance, availability, error rates, and for querying application logs (including custom traces from the Python code).
    * Local MLflow UI for reviewing, comparing, and analyzing past training experiments.

---

## 3. Project Structure
<img width="1202" alt="Screenshot 2025-05-09 175741" src="https://github.com/user-attachments/assets/6739cda6-5cee-4b1d-a267-d8fc91fc5bf6" />

**Folder and File Descriptions:**

* **`.github/workflows/`**: Contains the GitHub Actions workflow YAML file (`deploy-to-azure-app-service.yml`) that defines the CI/CD pipeline for building the Docker image, pushing it to ACR, and deploying it to Azure App Service.
* **`artifacts/`**: Stores non-model outputs generated by the training pipeline. This includes:
    * `confusion_matrix_valid.png`: Visualization of the model's performance on the validation set.
    * `feature_importance.png`: Plot showing the most important features for the model.
    * `final_training_features.json`: A JSON file listing the exact features used to train the model, crucial for ensuring consistency during inference.
    * `model_info.json`: A JSON file containing metadata about the trained model, such as MLflow run ID, training parameters, and key performance metrics.
* **`data/raw/`**: Designated directory for storing the original, unaltered input datasets (e.g., `train_transaction.csv`, `train_identity.csv`). These files are typically large and are not committed to the Git repository.
* **`data/processed/`**: Intended for storing dataframes after preprocessing and feature engineering steps, ready for model training (e.g., `final_processed_training_data.parquet`). Also generally not committed to Git.
* **`env/`**: Contains environment configuration files. `environment_scoring.yml` was likely used for defining a Conda environment for a previous Azure Machine Learning deployment approach.
* **`mlruns/`**: The default local directory where MLflow stores all experiment tracking data, including parameters, metrics, tags, and artifacts for each run. This directory is excluded from Git.
* **`models/`**: This critical directory stores the serialized trained machine learning model (`lgbm_model.joblib`) and any preprocessor objects (`label_encoders.joblib`, `pca_v_transformer.joblib`, `scaler_v_transformer.joblib`) that were fitted during the training pipeline and are necessary for transforming new data at inference time.
* **`notebooks/`**: Contains Jupyter notebooks (`fraud_ml_ops.ipynb`) used for initial data exploration, analysis, experimentation, and iterative model development.
* **`src/`**: The primary directory containing all Python source code for the project.
    * `__init__.py`: Marks the `src` directory as a Python package.
    * `config.py`: Defines global configuration variables, file paths, model hyperparameters, and other settings used throughout the project.
    * `data_preprocessing.py`: Houses functions responsible for loading raw data, cleaning it, handling missing values, and performing initial transformations like datetime processing and categorical encoding.
    * `feature_engineering.py`: Contains scripts for generating new, informative features from the preprocessed data to improve model performance.
    * `predict.py`: Implements the Flask web application. It loads the trained model and preprocessors, defines API endpoints (like `/api/predict`) for receiving input data, processes the input, makes predictions, and returns the results. It also serves the HTML interface.
    * `train.py`: Includes the core logic for training the LightGBM model, performing model evaluation on validation/test sets, and logging all relevant experiment details to MLflow locally.
    * `utils.py`: A collection of utility functions that support various tasks across the project, such as memory optimization.
* **`templates/`**: Contains HTML files (e.g., `index.html`) used by the Flask application to render a web-based user interface for making predictions.
* **`tests/`**: (To be developed) This directory will contain all unit tests and integration tests to ensure the correctness and reliability of the codebase.
* **Root Directory Files:**
    * `.dockerignore`: Specifies which files and directories should be excluded from the Docker build context to keep the image lean.
    * `.gitignore`: Lists files and directories that Git should ignore (e.g., virtual environments, local data, MLflow runs, sensitive configuration files).
    * `config.json`: Contains configuration details for connecting to an Azure Machine Learning workspace. *This file should be in `.gitignore` if it holds sensitive subscription or workspace IDs to avoid committing them to a public repository.*
    * `create_aml_scoring_env.py`, `deploy_to_aml_endpoint.py`, `register_aml_deployment_package.py`: These Python scripts were part of the initial MLOps strategy focused on deploying the model using Azure Machine Learning managed online endpoints. They handle the creation of scoring environments, registration of deployment packages, and deployment to AML endpoints. (Mention if these are now considered legacy or an alternative deployment path for specific scenarios).
    * `Dockerfile`: Contains the set of instructions for Docker to build the application image. It specifies the base Python image, copies necessary files (source code, models, artifacts, requirements), installs dependencies, and defines the command to run the Flask application.
    * `README.md`: This file, providing a comprehensive overview of the project.
    * `requirements.txt`: Lists all Python libraries and their versions required to run the project, ensuring a reproducible environment.
    * `run_pipeline.py`: The main executable script that orchestrates the entire local training pipeline. It calls functions from `data_preprocessing.py`, `feature_engineering.py`, and `train.py` in sequence to process data and train the model.
 
## 4. Installation, Setup, and Deployment Workflow

I. Local Development Environment Setup

These steps are for setting up the project on a local machine for development, training, and local testing.

Step 1: Clone the Repository

git clone https://github.com/bachdang0311/fraud_detection_mlops.git
cd fraud_detection_mlops

Step 2: Create and Activate Python Virtual Environment

# Ensure Python 3.11 is installed
python -m venv venv
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

Step 3: Install Python Dependencies

pip install -r requirements.txt

Step 4: Obtain and Place Raw Data

Download train_transaction.csv and train_identity.csv from the IEEE-CIS Fraud Detection Kaggle competition.

Create the directory data/raw/ if it doesn't exist.

Place the downloaded CSV files into the data/raw/ directory. (Raw data is not committed to Git.)

Step 5: Run Local Training Pipeline

python run_pipeline.py

This will:

Save fitted preprocessors and the trained model to models/

Save other artifacts to artifacts/

Log experiment details to the mlruns/ directory

Step 6: Review Training Experiments with MLflow UI (Local)

mlflow ui

Open http://localhost:5000 to inspect training runs.

Step 7: Test Flask Prediction API Locally

python -m src.predict

Flask app will be available at http://localhost:8080. Test the /api/predict endpoint using Postman or curl.

Step 8: (Optional) Build and Test Docker Image Locally

# Build
docker build -t fraud_detector_app_local:latest .
# Run
docker run -p 8080:8080 -e PORT=8080 fraud_detector_app_local:latest

Test the API at http://localhost:8080/api/predict

II. Azure Cloud Resource Setup (Manual One-time Setup)

Ensure you have Azure CLI installed and are logged in:

az login
az account set --subscription "<your-subscription-id>"

Step 9: Register Azure Resource Providers

az provider register --namespace Microsoft.Web --wait
az provider register --namespace Microsoft.Storage --wait
az provider register --namespace Microsoft.ContainerRegistry --wait

Step 10: Create Azure Resource Group

$NEW_RESOURCE_GROUP = "MyFraudRgAppServiceCI"
$LOCATION = "westus2"
az group create --name $NEW_RESOURCE_GROUP --location $LOCATION

Step 11: Create Azure Container Registry (ACR)

$NEW_ACR_NAME_CI = "myfraudappcicracr" + (Get-Random -Count 4 | ForEach-Object { [char]$_ }).ToLower()
az acr create --resource-group $NEW_RESOURCE_GROUP --name $NEW_ACR_NAME_CI --sku Basic --admin-enabled true

Step 12: Create Azure App Service Plan

$NEW_APPSERVICE_PLAN_CI = "myFraudAppPlanCI" + (Get-Random -Count 4 | ForEach-Object { [char]$_ }).ToLower()
az appservice plan create --name $NEW_APPSERVICE_PLAN_CI --resource-group $NEW_RESOURCE_GROUP --sku B1 --is-linux --location $LOCATION

Step 13: Create Azure App Service (Web App for Containers)

$NEW_WEBAPP_NAME_CI = "myfrauddetectorapici" + (Get-Random -Count 4 | ForEach-Object { [char]$_ }).ToLower()
az webapp create --resource-group $NEW_RESOURCE_GROUP `
                 --plan $NEW_APPSERVICE_PLAN_CI `
                 --name $NEW_WEBAPP_NAME_CI `
                 --deployment-container-image-name ""

az webapp config appsettings set --resource-group $NEW_RESOURCE_GROUP --name $NEW_WEBAPP_NAME_CI --settings WEBSITES_PORT=8080
az webapp log config --name $NEW_WEBAPP_NAME_CI --resource-group $NEW_RESOURCE_GROUP --docker-container-logging filesystem --level information

Step 14: Enable Application Insights

Go to Azure Portal → App Service → Monitoring → Application Insights

Click "Turn on" and create or link an existing resource.

Ensure opencensus-ext-azure is in requirements.txt

Configure logging in src/predict.py

III. CI/CD Setup with GitHub Actions

Step 15: Prepare Azure Credentials

ACR Admin Credentials: Azure Portal → ACR → Access keys → Enable Admin

App Service Publish Profile: Azure Portal → App Service → Overview → Get publish profile

Step 16: Add GitHub Secrets

Go to GitHub → Settings → Secrets → Actions. Add:

ACR_LOGIN_SERVER

ACR_USERNAME

ACR_PASSWORD

AZURE_WEBAPP_PUBLISH_PROFILE

AZURE_APP_NAME

IMAGE_NAME

Step 17: Create GitHub Actions Workflow File

Create .github/workflows/deploy-to-azure-app-service.yml

Paste your YAML configuration

Ensure environment variables map to GitHub secrets

Step 18: Commit and Push Project to GitHub

git init -b main
git config --global user.email "your_email@example.com"
git config --global user.name "Your Name"
git add .
git commit -m "Initial project commit with CI/CD workflow"
git remote add origin https://github.com/<YOUR_USERNAME>/<YOUR_REPOSITORY_NAME>.git
git push -u origin main

For existing repos, only add and push the new workflow file.

IV. Ongoing Development and Automated Deployment

Step 19: Make Code Changes or Retrain Model

python run_pipeline.py

Update files in models/, artifacts/, or src/ as needed.

Step 20: Push Changes to GitHub

git add .
git commit -m "Describe your changes"
git push origin main

Step 21: Monitor GitHub Actions Workflow

Go to GitHub → Actions tab → Track workflow status.

Step 22: Verify Deployment

Check http://.azurewebsites.net

Review logs via Application Insights

This setup provides a robust MLOps pipeline, from local development and model training to full cloud deployment and monitoring via CI/CD automation
